import numpy as np
import math
from sklearn.naive_bayes import GaussianNB

# 连续型数据分类用正态分布公式
def getPro(theData, mean, var):
    pro = 1 / (math.sqrt(2 * math.pi) * math.sqrt(var)) * math.exp(-(theData - mean) ** 2 / (2 * var))
    return pro


def getRandom(num):
    Ran = np.random.dirichlet(np.ones(num), size = 1)
    Ran = Ran.flatten()
    return Ran


'''
def CountP1(test):
    sum=1
    for i in range(0,60):
       sum*=getPro(test[i],
def CountP2(test):
    sum=1
    for i in  range(0,60):
        sum*=getPro(())
'''

X = np.loadtxt('[018]musk01(0-1).txt')
# 其中有97
m = X.shape[1] - 1  # 属性数量
n = X.shape[0]  # 样本数目
T = 4
K = 2  # 类标记数量
# 主要过程：分组
# 去掉类标记
Class1 = 0
Class2 = 0

for i in X:
    if i[m] == 1:
        Class1 = Class1 + 1
    elif i[m] == 2:
        Class2 = Class2 + 1

train1 = int(Class1 * 0.5)
val1 = int(Class1 * 0.2)
test1 = Class1 - train1 - val1

train2 = int(Class2 * 0.5)
val2 = int(Class2 * 0.2)
test2 = Class2 - train2 - val2

# 随机产生多少个和为1的随机数W
G1 = [7, 12, 22, 28, 32, 44, 47, 48, 53, 59, 62, 66, 67, 72, 73, 74, 77, 78, 79, 80, 105, 106, 108, 109, 110, 111, 125, 126, 134, 145, 150, 156, 159, 162, 164, 165] # 7
G2 = [1, 2, 3, 5, 6, 8, 10, 13, 14, 15, 16, 21, 23, 24, 25, 26, 27, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 51, 52, 54, 56, 57, 58, 60, 61, 63, 64, 68, 69, 70, 71, 76, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 102, 103, 104, 107, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 129, 130, 131, 135, 136, 137, 138, 141, 142, 143, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 160]# 3
G3 = [4, 30, 65, 75, 144, 146, 161, 163]
G4 = [0, 9, 11, 17, 18, 19, 20, 35, 42, 49, 50, 55, 82, 93, 94, 101, 115, 128, 132, 133, 139, 140]# 12
len1=len(G1)
len2=len(G2)
len3=len(G3)
len4=len(G4)
l1=len1
l2=len1+len2
l3=len1+len2+len3
l4=len1+len2+len3+len4
#随机训练集，验证集，测试集区

idx = np.random.choice(np.arange(Class1), size = train1, replace = False)
train_index1 = np.array(idx)
val_index1 = np.random.choice(np.delete(np.arange(Class1), train_index1), size = val1, replace = False)
test_index1 = np.delete(np.arange(Class1), np.append(train_index1, val_index1))

idx1 = np.random.choice(np.arange(Class2), size = train2, replace = False)
train_index2 = np.array(idx1)
val_index2 = np.random.choice(np.delete(np.arange(Class2), train_index2), size = val2, replace = False)
test_index2 = np.delete(np.arange(Class2), np.append(train_index2, val_index2))

print("train_index1 =",list(train_index1))
print("val_index1 =",list(val_index1))
print("test_index1 =",list(test_index1))
print("train_index2 =",list(train_index2))
print("val_index2 =",list(val_index2))
print("test_index2 =",list(test_index2))




#确认训练集，验证集，测试集区
train_index1 = [80, 82, 22, 10, 17, 29, 73, 133, 119, 186, 81, 156, 149, 47, 139, 198, 175, 122, 110, 75, 50, 39, 51, 141, 78, 83, 129, 32, 151, 173, 158, 142, 20, 170, 105, 178, 103, 44, 160, 108, 164, 30, 65, 19, 182, 154, 159, 107, 102, 150, 196, 134, 41, 127, 144, 99, 124, 131, 28, 88, 188, 100, 163, 183, 9, 90, 128, 191, 146, 38, 84, 101, 0, 23, 1, 61, 66, 46, 121, 195, 71, 97, 162, 27, 69, 43, 111, 48, 104, 113, 36, 137, 53, 117, 77, 49, 35, 72, 42, 120, 26, 118, 171]
val_index1 = [112, 125, 4, 7, 172, 132, 62, 153, 64, 93, 86, 115, 181, 59, 140, 180, 189, 57, 55, 40, 94, 126, 109, 13, 58, 68, 204, 177, 169, 6, 166, 155, 12, 203, 194, 114, 143, 200, 70, 34, 14]
test_index1 = [2, 3, 5, 8, 11, 15, 16, 18, 21, 24, 25, 31, 33, 37, 45, 52, 54, 56, 60, 63, 67, 74, 76, 79, 85, 87, 89, 91, 92, 95, 96, 98, 106, 116, 123, 130, 135, 136, 138, 145, 147, 148, 152, 157, 161, 165, 167, 168, 174, 176, 179, 184, 185, 187, 190, 192, 193, 197, 199, 201, 202, 205, 206]
train_index2 = [43, 228, 247, 206, 81, 25, 232, 48, 208, 195, 189, 231, 82, 119, 218, 66, 23, 27, 229, 240, 234, 58, 204, 198, 253, 157, 174, 192, 35, 62, 83, 69, 86, 220, 87, 129, 100, 0, 169, 12, 141, 10, 227, 226, 71, 173, 239, 113, 96, 245, 133, 238, 9, 45, 233, 241, 258, 70, 91, 164, 267, 153, 56, 159, 214, 221, 184, 235, 178, 89, 42, 24, 200, 216, 163, 244, 75, 183, 72, 117, 102, 94, 168, 176, 137, 19, 148, 242, 187, 106, 139, 77, 268, 97, 202, 151, 144, 134, 171, 146, 193, 111, 55, 230, 188, 181, 152, 256, 145, 107, 260, 118, 38, 124, 7, 104, 213, 156, 251, 185, 201, 158, 78, 50, 73, 127, 179, 196, 49, 209, 15, 126, 150, 20]
val_index2 = [39, 37, 76, 217, 67, 199, 224, 54, 8, 61, 108, 98, 14, 22, 248, 109, 147, 194, 215, 142, 205, 85, 3, 122, 74, 246, 11, 44, 64, 203, 31, 237, 121, 186, 207, 30, 182, 46, 219, 172, 222, 255, 197, 131, 166, 29, 26, 254, 1, 138, 90, 149, 36]
test_index2 = [2, 4, 5, 6, 13, 16, 17, 18, 21, 28, 32, 33, 34, 40, 41, 47, 51, 52, 53, 57, 59, 60, 63, 65, 68, 79, 80, 84, 88, 92, 93, 95, 99, 101, 103, 105, 110, 112, 114, 115, 116, 120, 123, 125, 128, 130, 132, 135, 136, 140, 143, 154, 155, 160, 161, 162, 165, 167, 170, 175, 177, 180, 190, 191, 210, 211, 212, 223, 225, 236, 243, 249, 250, 252, 257, 259, 261, 262, 263, 264, 265, 266]



W = getRandom(m * K) * 100
W=[0.03166670812439715, 0.003894537489680783, 0.007603028574718391, 0.013422360653883825, 0.04103746493539366, 0.009274587147580485, 0.05575323656941377, 0.09000254151038117, 0.007926495158219042, 0.023938478339956666, 0.051014552738624236, 0.037034109385359636, 0.08489422344588823, 0.025994516419269607, 0.014142899065900888, 0.021237843916301343, 0.04187499872044108, 0.028302430865081066, 0.059788907770294615, 0.004332931867895637, 0.05210913458576007, 0.027863248819432918, 0.03166026486180853, 0.0046138305443717545, 0.014760944880535998, 0.02564172583899727, 0.021495021673820888, 0.002024632353564165, 0.04630249182267747, 0.015574908906295351, 0.018025596805700407, 0.06632805412617938, 0.004234954595525103, 0.0639414045618957, 0.011015751480963128, 0.04484045404629834, 0.04140221620999634, 0.026445666284002578, 0.014346107421343488, 0.017127908826581124, 0.008395341425652916, 0.07379082632591602, 0.006170437584242431, 0.0053083570270575, 0.006461178087424382, 0.0015696391663585188, 0.03655030871325905, 0.012171198085093387, 0.035250472378821174, 0.009065828785366959, 0.018017079718928027, 0.04685319660164934, 0.011898155511188306, 0.029642474505943792, 0.049468282609597666, 0.027941267436409904, 0.05621554157882121, 0.03001135043220532, 0.013015209749922981, 0.010581293803233128, 0.004626974376246758, 0.05440859107782501, 0.017716621313374835, 0.001125231750130794, 0.04844016590239479, 0.00490871716238129, 0.04222466139628646, 0.07388956909220952, 0.016165968385186417, 0.03887073828372256, 0.024173296038081403, 0.006886021290358228, 0.002590488055023572, 0.015631053948643153, 0.03567702893716754, 0.12812535995910315, 0.052892384962385554, 0.008997582380716919, 0.014602085318659322, 0.004791701732683954, 0.03323599556133241, 0.00613606853424471, 0.017247309367680708, 0.0004034267782308318, 0.017218004029792486, 0.05469017473508544, 0.04289720354044939, 0.018302675922371038, 0.013973359706259906, 0.006528149998290566, 0.0029624732598172, 0.024767990520075372, 0.04348538035265438, 0.014157339800702693, 0.07527890311610487, 0.05215310312323812, 0.04113792889130278, 0.026033050588781734, 0.03551078064880736, 0.006321110569757582, 0.043468940442853585, 0.06203027508076876, 0.04760572443421317, 0.06835604959959332, 0.022158737604627898, 0.02294018941089273, 0.004942083369096023, 0.00297293353020666, 0.02229119770150626, 0.01294376433099669, 0.0003347239527876976, 0.018625098736501037, 0.005460544544186372, 0.01692337850780628, 0.00660842581030267, 0.007595515705135964, 0.028560276053074627, 0.04427499598060588, 0.04832613099886597, 0.013395044433979507, 0.010414399578118664, 0.02719465008375522, 0.0146278503611276, 0.012472859755219229, 0.04052620811492029, 0.015190613654893473, 0.1181649017178678, 0.03314472093837857, 0.08143156848767465, 0.11438564952983354, 0.08296865619968599, 0.0012930000362780412, 0.021652491889796496, 0.03941185359641587, 0.022182014201628332, 0.014996649754977796, 0.02650127785065763, 0.0024263171495048134, 0.05431003367588491, 0.0007244802732959087, 0.036213761502925323, 0.00974201045971353, 0.014829019796348644, 0.01829509711840602, 0.06698265889656692, 0.01712592927561287, 0.12932614757341482, 0.04901837719435806, 0.005197901278933411, 0.04848663136715921, 0.047904831532520176, 0.003969553250183317, 0.022387928769176016, 0.03406808720100633, 0.02211881187699763, 0.03241063171908922, 0.026498988283833277, 0.008600170942341744, 0.05673663839245454, 0.08343734972400715, 0.01253754871644079, 0.04703707947536341, 0.004256550588663928, 0.02606134664549823, 0.03310020897574482, 0.003812262758538627, 0.07721237353330279, 0.022163101443409904, 0.0002678032156825251, 0.012340764931036191, 0.007760825213719893, 0.0783263519204421, 0.0698373767806835, 0.034354481873159454, 0.03747891054589632, 0.018251801632013568, 0.04803830602038726, 0.05851857841719747, 0.10052291574193273, 0.041149264904741724, 0.042891531326160554, 0.0014884169344844538, 0.010833191924512367, 0.0075634673019930945, 0.020628788981608397, 0.022019566169587106, 0.00715048210454886, 0.029783352967367435, 0.01179286969777869, 0.0019692217163487773, 0.013654964267610481, 0.021804358191826054, 0.009490124790357957, 0.05061926472612764, 0.05982933137586622, 0.01922885956343405, 0.005732436016128325, 0.004610474788190132, 0.00468995899731914, 0.012609456107324673, 0.003905463113562525, 0.02743702971957697, 0.015421600299819697, 0.00213160119155542, 0.021649404896304722, 0.10441955685867826, 0.009822940718432906, 0.01311112053145785, 0.017327398090526004, 0.06124141121571092, 0.06117787057276, 0.003775703254486065, 0.0785659300513322, 0.042426005822419094, 0.0013733349535244362, 0.07730400834878888, 0.004625299946249966, 0.10324657508316518, 0.12097045722797502, 0.025719501303534707, 0.018342729987519, 0.010105887427094201, 0.07934105627128726, 0.029594776369222614, 0.018567463220802705, 0.029484322655533607, 0.0001457116657685033, 0.08616071665480111, 0.017472142592161843, 0.005551966040806467, 0.011186570594475287, 5.82600935839964e-05, 0.010911520187766251, 0.00817289411258004, 0.010445487091276013, 0.09253996792351796, 0.015186146541039794, 0.05272564503186025, 0.0011918115354335869, 0.011590024455981687, 0.11104013200500959, 0.03359468182171845, 0.011871822706334119, 0.003974710906321911, 0.06509881937550793, 0.005956637588798797, 0.011093936674409255, 0.04268113292234188, 0.054146757186844675, 0.05800339911498, 0.0042512800804581675, 0.08712011379528879, 0.020260092045538566, 0.0025838016548947918, 0.023041171640295625, 0.0026671798933663444, 0.03324526103095681, 0.020868317589402406, 0.0390957177966934, 0.11738196566138981, 0.039575240890111225, 0.0003417805280417224, 0.004092394990705642, 0.018457529406841033, 0.01364601297335501, 0.023204236526567605, 0.016843693730208574, 0.001908014305312719, 0.016557364355209183, 0.11234820654572955, 0.028244492833249195, 0.025272645689226828, 0.03987347953554227, 0.07478737935741467, 0.050961826724619734, 0.04113614424611475, 0.004048506203227669, 0.013793598829679576, 0.10371091012408386, 0.0029854368188951376, 0.028151289368933463, 0.14474514626790214, 0.027484469387337142, 0.07952103436977645, 0.02353292130604214, 0.023278303796362518, 0.03163977321955689, 0.0005772415451774568, 0.041091772974023374, 0.0011586246153817718, 0.012120896344814749, 0.0023471488082772106, 0.021704969617546373, 0.06122518040016956, 0.004291928068682174, 0.05104384265810542, 0.025855573640627506, 0.030094838744508457, 0.007362929325132553, 0.008723162243146173, 0.04074634947195778, 0.005991887851874017, 0.019729709244217984, 0.027005965545415265, 0.03382846644564076, 0.01958089038673916, 0.04580681907288818, 0.002632526751935943, 0.0017129415089831436, 0.061406031853189214, 0.01943071437866033, 0.012678740219900593, 0.0937556932087423, 0.004792453080372497, 0.0017949065305179646, 0.021572758058328367, 0.008048049295353838, 0.0004207077857940807, 0.01717153165591965, 0.007534232568837356, 0.0048855503140240834, 0.0068075270736844655, 0.047812127392389644, 0.04737959027183599, 0.04131496281632155, 0.04588233343528258, 0.018204718973318063, 0.05336527181801356, 0.03958256416983912, 0.03391811914095661, 0.012114131880232644, 0.013891535545792609]


NewArray = np.ones((Class1, T + 1))
# 第0组
W1 = W[0:l1]
for i in range(0, Class1):
    add1 = 0
    for j in range(0, len1):
        add1 += W1[j] * X[i, G1[j]]
    NewArray[i][0] = add1
# 第1组
W2 = W[l1:l2]
for i in range(0, Class1):
    add2 = 0
    for j in range(0, len2):
        add2 += W2[j] * X[i, G2[j]]
    NewArray[i][1] = add2
# 第2组
W3 = W[l2:l3]
for i in range(0, Class1):
    add3 = 0
    for j in range(0, len3):
        add3 += W3[j] * X[i, G3[j]]
    NewArray[i][2] = add3
# 第三组
W4 = W[l3:l4]
for i in range(0, Class1):
    add4 = 0
    for j in range(0, len4):
        add4 += W4[j] * X[i, G4[j]]
    NewArray[i][3] = add4
# print(NewArray)

# 求类2的分组情况
NewArray1 = np.ones((Class2, T + 1)) * 2
# 第0组
W5 = W[l4:l4 + l1]
for i in range(Class1, n):
    add1 = 0
    for j in range(0, len1):
        add1 += W5[j] * X[i, G1[j]]
    NewArray1[i - Class1][0] = add1
# 第1组
W6 = W[l4 + l1:l4 + l2]
for i in range(Class1, n):
    add2 = 0
    for j in range(0, len2):
        add2 += W6[j] * X[i, G2[j]]
    NewArray1[i - Class1][1] = add2
# 第2组
W7 = W[l4 + l2:l4 + l3]
for i in range(Class1, n):
    add3 = 0
    for j in range(0, len3):
        add3 += W7[j] * X[i, G3[j]]
    NewArray1[i - Class1][2] = add3
# 第三组
W8 = W[l4 + l3:l4 + l4]
for i in range(Class1, n):
    add4 = 0
    for j in range(0, len4):
        add4 += W8[j] * X[i, G4[j]]
    NewArray1[i - Class1][3] = add4
NewArray = np.vstack((NewArray, NewArray1))
print(NewArray)

# 随机抽取样本训练集和测试集样本

X1 = NewArray[0:Class1, :]
X2 = NewArray[Class1:Class1 + Class2, :]

Data1 = X1[train_index1, :]
Data2 = X2[train_index2, :]
trainSet=np.vstack((Data1,Data2))
Y=trainSet[:,T]
trainSet=np.delete(trainSet,T,axis = 1)

testSet1 = np.delete(X1[test_index1, :], T, axis = 1)
testSet2 = np.delete(X2[test_index2, :], T, axis = 1)
trainSet1 = np.delete(Data1, T, axis = 1)
trainSet2 = np.delete(Data2, T, axis = 1)
valSet1=np.delete(X1[val_index1,:],T,axis = 1)
valSet2=np.delete(X2[val_index2,:],T,axis = 1)

# 求各类对应属性的均值和方差
Mean1 = np.mean(trainSet1, axis = 0)
Mean2 = np.mean(trainSet2, axis = 0)
# print(Mean2)
var1 = np.var(trainSet1, axis = 0)
var2 = np.var(trainSet2, axis = 0)



clf=GaussianNB()

clf.fit(trainSet,Y)

C1 = clf.predict(trainSet1)
add = sum(C1 == 1)
print("第一类正确数量(总数):", train1)
print(add)
C2 = clf.predict(trainSet2)
add1 = sum(C2 == 2)
print("第二类正确数量(总数)：", train2)
print(add1)

print("accuracy:{:.2%}".format((add + add1) / (train1+train2)))



